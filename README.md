# üöÄ Architecture Big Data ‚Äì Pipeline d‚ÄôIngestion de Logs

![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Hadoop](https://img.shields.io/badge/Apache_Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)
![OpenSearch](https://img.shields.io/badge/OpenSearch-005EB8?style=for-the-badge&logo=opensearch&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

Ce projet met en place une **architecture Big Data compl√®te**, enti√®rement conteneuris√©e avec **Docker**, permettant :

- l‚Äôingestion de logs applicatifs,
- leur stockage distribu√© dans **Hadoop HDFS**,
- leur transformation via un script **Python ETL**,
- leur indexation dans **OpenSearch**,
- leur visualisation via **OpenSearch Dashboards**.

---

## üìë Table des Mati√®res
- [Architecture](#-architecture)
- [Pr√©requis](#-pr√©requis)
- [Structure du Projet](#-structure-du-projet)
- [Installation et D√©marrage](#-installation-et-d√©marrage)
- [Utilisation du Pipeline](#-utilisation-du-pipeline)
- [Visualisation](#-visualisation)
- [Auteur](#-auteur)

---

## üèó Architecture

L‚Äôinfrastructure repose sur un r√©seau Docker unique (`tp-network`) compos√© de :

### üî∑ Cluster Hadoop (3 n≈ìuds)
- **NameNode + ResourceManager**
  - Gestion des m√©tadonn√©es HDFS
  - Supervision YARN
- **2√ó DataNodes + NodeManagers**
  - Stockage distribu√©
  - Ex√©cution des t√¢ches YARN

### üî∑ Cluster OpenSearch (2 n≈ìuds)
- Stockage index√© des logs transform√©s
- Recherche rapide full-text

### üî∑ OpenSearch Dashboards
- Interface graphique pour l‚Äôexploration et la cr√©ation de visualisations  
  *(http://localhost:5601)*

### üî∑ Script ETL Python (conteneur √©ph√©m√®re)
- **Extract** : lecture des fichiers depuis HDFS  
- **Transform** : parsing via Regex  
- **Load** : indexation dans OpenSearch  

---

## üõ† Pr√©requis

- Docker & Docker Compose
- Windows, Linux ou macOS
- 8‚Äì16 Go de RAM recommand√©s
- Sur Linux/WSL, configurer :
  ```bash
  sudo sysctl -w vm.max_map_count=262144

  # Projet ETL de Logs (Hadoop & OpenSearch)

Ce projet d√©ploie un pipeline complet pour l'ingestion, le traitement et la visualisation de logs d'acc√®s web en utilisant **Hadoop (HDFS)** pour le stockage et **OpenSearch** pour l'indexation et l'analyse.

## üìÇ Structure du Projet

```
tp-final/
‚îú‚îÄ‚îÄ docker-compose.yml   # D√©ploiement complet Hadoop + OpenSearch
‚îú‚îÄ‚îÄ hadoop.env           # Configuration des services Hadoop
‚îú‚îÄ‚îÄ etl.py               # Script Python ETL
‚îú‚îÄ‚îÄ access.log           # Fichier de logs source
‚îî‚îÄ‚îÄ README.md            # Documentation
```

## üöÄ Installation et D√©marrage

### 1Ô∏è‚É£ Lancer les services

Utilisez Docker Compose pour d√©marrer tous les conteneurs n√©cessaires (NameNode, DataNode, OpenSearch, etc.).

```bash
docker-compose up -d
```

> ‚è≥ **Attendre 2 √† 3 minutes** avant utilisation (le temps d'initialisation du NameNode et d'OpenSearch est crucial).

### 2Ô∏è‚É£ V√©rifier l‚Äô√©tat

V√©rifiez que tous les services sont en cours d'ex√©cution.

```bash
docker-compose ps
```

## üîÑ Utilisation du Pipeline

### üßÆ √âtape 1 ‚Äî G√©n√©rer un fichier de logs (exemple PowerShell)

Pour simuler des donn√©es de logs, ex√©cutez ces commandes (ou leurs √©quivalents dans votre shell) pour cr√©er un fichier `access.log`.

```powershell
Set-Content access.log "192.168.1.10 - - [21/Nov/2025:10:00:00 +0000] ""GET /index.html HTTP/1.1"" 200 1024"
Add-Content access.log "192.168.1.11 - - [21/Nov/2025:10:05:00 +0000] ""POST /login HTTP/1.1"" 403 512"
Add-Content access.log "192.168.1.12 - - [21/Nov/2025:10:10:00 +0000] ""GET /dashboard HTTP/1.1"" 200 2048"
Add-Content access.log "192.168.1.13 - - [21/Nov/2025:10:15:00 +0000] ""GET /missing-page HTTP/1.1"" 404 128"
Add-Content access.log "192.168.1.10 - - [21/Nov/2025:10:20:00 +0000] ""DELETE /user/1 HTTP/1.1"" 500 0"
```

### üóÇ √âtape 2 ‚Äî Copier le fichier dans HDFS

Transf√©rez le fichier `access.log` local dans le syst√®me de fichiers distribu√© Hadoop (HDFS).

```bash
# Copier le fichier local vers le conteneur NameNode
docker cp access.log namenode:/tmp/access.log

# Cr√©er le r√©pertoire dans HDFS
docker exec namenode hdfs dfs -mkdir -p /user/logs_tp

# Placer le fichier dans HDFS (utilisation de -f pour forcer l'√©crasement si d√©j√† pr√©sent)
docker exec namenode hdfs dfs -put -f /tmp/access.log /user/logs_tp/
```

### ‚öôÔ∏è √âtape 3 ‚Äî Ex√©cuter le script ETL

Ex√©cutez le script Python `etl.py` pour lire les logs depuis HDFS, les transformer et les indexer dans OpenSearch.

```bash
docker run --rm -it --network=tp-final_tp-network -v "${PWD}/etl.py:/etl.py" python:3.9-slim bash -c "pip install hdfs opensearch-py && python /etl.py"
```

Si l'ex√©cution est r√©ussie, vous devriez voir une sortie similaire √† :

```
‚úÖ Log index√© : ...
üéâ Migration termin√©e avec succ√®s !
```

## üìä Visualisation

Acc√©dez √† OpenSearch Dashboards pour visualiser les donn√©es index√©es.

### Acc√®s

Ouvrez votre navigateur et acc√©dez √† :

```
http://localhost:5601
```

### Cr√©ation de l'Index Pattern

1.  Allez dans **Stack Management** ‚Üí **Index Patterns**.
2.  Cliquez sur **Create index pattern**.
3.  Entrez le pattern suivant :

```
logs-app-*
```

### Exploration et Dashboards

* **Menu Discover :**
    * Explorez les logs index√©s pour v√©rifier la bonne ingestion des donn√©es.
* **Menu Visualize :**
    * Cr√©ez vos dashboards personnalis√©s (par exemple : un histogramme des codes HTTP, une carte des adresses IP, etc.).
